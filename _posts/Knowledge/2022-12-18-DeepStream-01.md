---
layout: post
title: "DeepStream 01: Introduction"
subtitle: "Introduction"
author: "NAB"
header-img: "img/in-post/2022/Dec/nvidia_wallpaper.jpg"
# header-style: text
header-mask: 0.4
lang: vi
catalog: true
# hidden: false
section: Knowledge
seo-keywords:
  - NVIDIA
  - GStreamer
  - Install
  - deepstream
  - deepstream-sdk
  - nvidia-deepstream
tags:
  - NVIDIA
  - DeepStream
---

# NVIDIA DeepStreame Overview

DeepStream một công cụ phân tích luồng xây dựng ứng dụng chạy bằng AI. Nó nhận luồng dữ liệu phát trực tiếp làm đầu vào - từ USB/CSI camera, video từ tệp hoặc được stream qua RTSP, đồng thời sử dụng AI và Computer Vision để tạo thông tin chi tiết từ các pixel để hiểu ra hơn về môi trường. DeepStream SDK có thể là lớp nền tảng cho một số giải pháp phân tích video như phân tích giao thông, người đi bộ trong thành phố thông minh (smart city), giám sát sức khỏe và an toàn trong y tế, tự kiểm tra và phân tích trong bán lẻ, phát hiện sản phẩm lỗi trong các dây chuyền sản xuất, ...

![DeepStream Overview](/img/in-post/2022/Dec/Knowledge/deepstream/DeepStream_Overview.png "DeepStream Overview")

DeepStream hỗ trợ phát triển ứng dụng bằng C/C++ và bằng Python thông qua các liên kết Python. Để dễ dàng hơn khi bắt đầu, DeepStream cung cấp một số ứng dụng tham khảo bằng cả C/C++ và Python. Xem chi tiết các phần [C/C++ Sample Apps Source Details](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_C_Sample_Apps.html) và [Python Sample Apps and Bindings Source Details](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_Python_Sample_Apps.html) để tìm hiểu hơn về các ứng dụng sẵn có. Xem [NVIDIA-AI-IOT](https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps) Github page để xem vài ví dụ tham khảo về ứng dụng DeepStream.

Nhân (Core) SDK bao gồm nhiều plugins tăng tốc độ phần cứng sử dụng các trình tăng tốc độ như VIC, GPU, DLA, NVDEC và NVENC. Bằng việc thực hiện tất cả các tính toán hoạt động nặng trong một trình tăng tốc chuyên dụng. DeepStream có thể đạt hiệu suất cao nhất cho các ứng dụng phân tích video. Một trong những khả năng chính của DeepStream là giao tiếp hai chiều an toàn giữ **edge** và **cloud**. DeepStream cung cấp một số giao thức bảo mật vượt trội như xác thực SASL/Plain sử dụng username/password và xác thực 2 chiều TLS. Để tìm hiểu thêm về các tính năng bảo mật này, hãy đọc chương [IOT](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_IoT.html). Để tìm hiểu các phần về các khả hai chiều, xem phần [Bidirectional Messaging](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_IoT.html#bi-directional-label) trong hướng dẫn.

DeepStream xây dựng bên trên một số thư viện NVIDIA GPUs; ứng dụng có thể được triển khai trên một **edge device** nhúng chạy nền tảng Jetson hoặc có thể được triển khai trên các **edge** or **datacenter** GPUs lớn như T4. Các ứng dụng DeepStream có thể được được triển khai trong các **containers** sử dụng **NVIDIA container Runtime**. Các **containers** hiện đang có sẵn trên NGC, NVIDIA GPU cloud registry. Để tìm hiểu hơn về triển khai với dockers xem chương Docker container. Các ứng dụng DeepStream có thể được sắp xếp trên **edge** bằng Kuberneters trên GPU. Biểu đồ mẫu Helm để triển khai ứng dụng DeepStream có sẵn trên NGC.

### DeepStream Graph Architecture

DeepStream là một kiến trúc đồ thị tối ưu xây dựng sử dung mã nguồn mở GStreamer framework. Đồ thị dưới đây trình bày một ứng dụng phân tích video bắt đầu từ input video đến thông tin chi tiết output. Tất cả các khối riêng lẻ là các plugin khác nhau được sử dụng. Ở dưới cùng là các công cụ phần cứng khác nhau được sử dụng trong toàn bộ ứng dụng. Quản lý bộ nhớ tối tưng với zero-memory copy giữa các plugins và việc sử dụng các trình tăng tốc khác nhau đảm bảo hiệu suất cao nhất.

![DeepStream overview graph architecture](/img/in-post/2022/Dec/Knowledge/deepstream/DS_overview_graph_architecture.png "DeepStream overview graph architecture")

DeepStream cung cấp các khối xây dựng dưới dạng các plugin GStreamer có thể được sử dụng để xây dựng pipeline phân tích video hiệu quả. Có hơn 20 plugins khác nhau được tăng tốc phần cứng cho các tác vụ khác nhau.

* Truyền dữ liệu có thể đi qua mạng thông qua RTSP hoặc từ các local file hệ thộng hoặc trực tiếp từ camera. Các luồng được capture sử dụng CPU. Sau khi các frames nằm  trong bộ nhớ, chúng sẽ được gửi để giải mã (decode) bằng bộ tăng tốc NVDEC. Plugin để giải mã được gọi là [`Gst-nvvideo4linux2`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvvideo4linux2.html).
* Sau khi giải mã, có một bược tiền xử lý ảnh, trong đó hình ảnh đầu vào có thể được tiền xử lý trước khi inference. Trong tiền xử lý ảnh có thể là dewraping (hiệu chỉnh biến dạng của ảnh) hoặc color space conversion (chuyển đôi không gian màu). Plugin [`Gst-nvdewraper`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvdewarper.html) có thể dewrap ảnh tử camera fisheye hoặc camera 360 độ. Plugin [`Gst-nvvideoconvert`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvvideoconvert.html) có thể thực hiện chuyển đổi định dạng màu sắc trên các frame. Các plugins này sử dụng GPU hoặc VIC (Vision Image Compositor - Bộ tổng hợp Vision Image).
* Bước tiếp theo là chia các frame này vào các batch để có hiệu suất inference tối ưu. Việc chia batch được thực hiện bằng cách sử dụng plugin [`Gst-nvstreammux`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvstreammux.html).
* Khi các frames đã được chia thành các batch, nó sẽ được gửi để inference. Việc suy luận có thể được thực hiện sử dụng **TensorRT**, bộ tăng tốc **NVIDIA inference runtime**  hoặc có thể thực hiện sử dụng các framework gốc như **TensorFlow** hoặc **PyTorch** sử dụng **Triton inference server**. **Native TensorRT** inference được thực hiện sử dụng plugin [`Gst-nvinfer`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvinfer.html), và inference bằng **Triton** được thực hiện bằng plugin [`Gst-nvinferserver`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvinferserver.html).  Inference có thể sử dụng GPU hoặc DLA (Deep Learning Accelerator) cho Jetson AGX Xavier và Xavier NX.
* Sau khi inference, bước tiếp theo có thể liên quan đến việc theo dõi đối tượng (tracking the object). Có một số **trackers** để tham khảo trong SDK, từ hiệu suất cao đến độ chính xác cao. Object tracking được thực hiện sử dụng plugin [`Gst-nvtracker`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvtracker.html).
* Để tạo các tạo các biểu diễn trực quan như là các bounding boxes, segmentation mask, labels, có một visualization plugin gọi là [`Gst-nvdsosd`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvdsosd.html).
* Cuối cùng để xuất kết quả, DeepStream trình bày nhiều tùy chọn khác nhau: reder output với các bouding boxes trên màn hình, lưu output vào local disk, stream qua RTSP hoặc chỉ gửi metadata lên cloud. Để  gửi gửi metadata lên cloud, DeepStream sử dụng các plugin [`Gst-nvmsgconv`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvmsgconv.html) và [`Gst-nvmsgbroker`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvmsgbroker.html). [`Gst-nvmsgconv`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvmsgconv.html) chuyển đổi metadata thành schema payload và [`Gst-nvmsgbroker`](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvmsgbroker.html) thiết lập kết nối với cloud và gửi dữ liệu đo xa. Có một số giao thức trung gian thích hợp như Kafka, MQTT, AMQP và Azure IoT. Bộ điều hợp trung gian tùy chỉnh có thể được tạo.

### DeepStream reference app

### Getting started with building apps

### DeepStream in Python






# Conclusion

----

# References

* [Basic tutorial 6: Media formats and Pad Capabilities](https://gstreamer.freedesktop.org/documentation/tutorials/basic/media-formats-and-pad-capabilities.html?gi-language=c#conclusion)
