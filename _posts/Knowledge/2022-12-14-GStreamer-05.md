---
layout: post
title: "GStreamer 05: Basic tutorial 3"
subtitle: "Dynamic pipelines"
author: "NAB"
header-img: "img/in-post/2022/Dec/nvidia_wallpaper.jpg"
# header-style: text
header-mask: 0.4
lang: vi
catalog: true
# hidden: false
section: Knowledge
seo-keywords:
  - NVIDIA
  - GStreamer
  - Install
  - install-gstreamer
  - nvidia-gstreamer
  - GStreamer_tutorial
  - gstreamer_dynamic_pipelines
tags:
  - NVIDIA
  - GStreamer
---

# Goal

Bài hướng dẫn này là phần còn lại của các khái niệm cơ bản cần thiết để sử dụng GStreamer, cho phép xây dựng pipeline "nhanh chóng", khi có sẵn thoomng tin, thay vì có một pipeline nguyên khối được định nghĩa khi bắt dầu ứng dụng của bạn

Sau bài hướng dẫn này, bạn sẽ có được kiến thức cần thiết để bắt đầu [Playback tutorial](). Các điểm được xem xét ở đây sẽ là:

* Cách để đạt được sự kiểm soát ttoots hơn khi liên kết các phần tử
* Cách để được thông báo về một sự kiện quan tâm để bạn có thể phản ứng kịp thời
* Các trạng thái khác nhau một phần tử có thể.

# Introduction

Như bạn sắp thấy, pipeline trong bài hướng dẫn này chưa được xây dựng hoàn chỉnh trước khi nó được đặt trạng thái "đang phát - playing". Điều này vẫn ổn. Nếu chúng ta không làm thêm gì nữa, dữ liệu sẽ đến cuối pipeline và dừng lại.

Trong ví dụ này, chúng ta đang mở một file được ghép kênh - multiplexed (hoặc trộn lẫn - muxed), nghĩa là, âm thanh và hình ảnh được lưu trữ cùng nhau trong file chứa (container file). Các phần tử chịu trách nhiệm mở các containers được gọi là các *bộ giải mã*  *(demuxers)*, một vài ví dụ về các định dạng của container là Matroska(MKV), Quick Time (QT, MOV), Ogg, hoặc Advanced Systems Format (ASF, WMV, WMA).

Nếu một container nhúng nhiều luồng (ví dụ, 1 video và 2 track âm thanh), demuxer sẽ tách chúng và cho chúng ra thông qua các cổng (port) đầu ra khác nhau. Theo cách này, các nhánh khác nhau có thể được tạo trong pipeline, xử lý các loại dữ liệu khác nhau.

Các cổng (port) mà qua đó các phần tử GStreamer giao tiếp với nhau được gọi là pads (`GstPad`). Tồn tại các **sink pads, qua đó dữ liệu đi vào một phần tử** và **các source pads, qua đó dữ liệu thoát ra khỏi một phần tử**. Theo lẽ tự nhiên, các phần tử source chỉ chứa các source pads, các phần tử sink chỉ chứa các sink pads, và các phần tử bộ lọc (filter) chứa cả hai.

![Source element](/img/in-post/2022/Dec/Knowledge/basic_tutorial_3/src-element.png "Source element")

![Filter element](/img/in-post/2022/Dec/Knowledge/basic_tutorial_3/filter-element.png "Filter element")

![Sink element](/img/in-post/2022/Dec/Knowledge/basic_tutorial_3/sink-element.png "Sink element")

_**Hình 1:** Các phần tử GStreamer và các pads của chúng._

**Một bộ giải mã** (demuxer) chứa **một sink pad, qua đó dữ liệu hỗn hợp (muxed data) đến** , và **nhiều source pads, mỗi cái cho mỗi luồng được tìm thấy trong container**:

![Filter element multi](/img/in-post/2022/Dec/Knowledge/basic_tutorial_3/filter-element-multi.png "Filter element multi")

_**Hình 2:** Một demuxer với hai source pads._

Để hoàn thiện hơn, dưới đây là một pipeline được đơn giản hóa chứa một bộ giải mã (demuxer) và hai nhánh, một cho âm thanh và một cho hình ảnh. Đây **không phải** pipeline sẽ được xây dựng trong bài hướng dẫn này.

![Example pipeline with two branches](/img/in-post/2022/Dec/Knowledge/basic_tutorial_3/simple-player.png "Example pipeline with two branches")

_**Hình 3:** Ví dụ pipeline với hai nhánh._

Sự phức tạp chính khi xử lý bộ giải mã là chúng không thể tạo ra bất kỳ thông tin nào cho đến khi chúng nhận được một số dữ liệu và có cơ hội để xem container bên trong có gì. Nghĩa là, các bộ giải mã bắt đầu không có các source pads mà các phần tử khác có thể liên kết đến và do đó pipeline nhất định phải keetss thúc tại chúng

Giải pháp là xây dựng pipeline từ source xuống bộ giải mã (demuxer), và đặt nó chạy (play). Khi demuxer nhận đủ thông tin để biết về số lượng và loại luồng trong container, nó sẽ bắt đầu tạo các source pads. Đây là lúc thích hợp để để chúng ta hoàn thành việc xây dựng pipeline và gắn nó vào các demuxer pads mới được thêm vào.

Để đơn giản hóa, trong ví dụ này, chúng ta chỉ liên kết với audio pad và bỏ qua video.

# Dynamic Hello World

* Copy đoạn code này vào file tên `basic_tutorial_3.c`

```c
#include <gst/gst.h>

/* Structure to contain all our information, so we can pass it to callbacks */
typedef struct _CustomData
{
    GstElement *pipeline;
    GstElement *source;
    GstElement *convert;
    GstElement *resample;
    GstElement *sink;
} CustomData;

/* Handler for the pad-added signal */
static void pad_added_handler(GstElement *src, GstPad *pad, CustomData *data);

int main(int argc, char *argv[])
{
    CustomData data;
    GstBus *bus;
    GstMessage *msg;
    GstStateChangeReturn ret;
    gboolean terminate = FALSE;

    /* Initialize GStreamer */
    gst_init(&argc, &argv);

    /* Create the elements */
    data.source = gst_element_factory_make("uridecodebin", "source");
    data.convert = gst_element_factory_make("audioconvert", "convert");
    data.resample = gst_element_factory_make("audioresample", "resample");
    data.sink = gst_element_factory_make("autoaudiosink", "sink");

    /* Create the empty pipeline */
    data.pipeline = gst_pipeline_new("test-pipeline");

    if (!data.pipeline || !data.source || !data.convert || !data.resample || !data.sink)
    {
        g_printerr("Not all elements could be created.\n");
        return -1;
    }

    /* Build the pipeline. Note that we are NOT linking the source at this
     * point. We will do it later. */
    gst_bin_add_many(GST_BIN(data.pipeline), data.source, data.convert, data.resample, data.sink, NULL);
    if (!gst_element_link_many(data.convert, data.resample, data.sink, NULL))
    {
        g_printerr("Elements could not be linked.\n");
        gst_object_unref(data.pipeline);
        return -1;
    }

    /* Set the URI to play */
    g_object_set(data.source, "uri", "https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm", NULL);

    /* Connect to the pad-added signal */
    g_signal_connect(data.source, "pad-added", G_CALLBACK(pad_added_handler), &data);

    /* Start playing */
    ret = gst_element_set_state(data.pipeline, GST_STATE_PLAYING);
    if (ret == GST_STATE_CHANGE_FAILURE)
    {
        g_printerr("Unable to set the pipeline to the playing state.\n");
        gst_object_unref(data.pipeline);
        return -1;
    }

    /* Listen to the bus */
    bus = gst_element_get_bus(data.pipeline);
    do
    {
        msg = gst_bus_timed_pop_filtered(bus, GST_CLOCK_TIME_NONE,
                                         GST_MESSAGE_STATE_CHANGED | GST_MESSAGE_ERROR | GST_MESSAGE_EOS);

        /* Parse message */
        if (msg != NULL)
        {
            GError *err;
            gchar *debug_info;

            switch (GST_MESSAGE_TYPE(msg))
            {
            case GST_MESSAGE_ERROR:
                gst_message_parse_error(msg, &err, &debug_info);
                g_printerr("Error received from element %s: %s\n", GST_OBJECT_NAME(msg->src), err->message);
                g_printerr("Debugging information: %s\n", debug_info ? debug_info : "none");
                g_clear_error(&err);
                g_free(debug_info);
                terminate = TRUE;
                break;
            case GST_MESSAGE_EOS:
                g_print("End-Of-Stream reached.\n");
                terminate = TRUE;
                break;
            case GST_MESSAGE_STATE_CHANGED:
                /* We are only interested in state-changed messages from the pipeline */
                if (GST_MESSAGE_SRC(msg) == GST_OBJECT(data.pipeline))
                {
                    GstState old_state, new_state, pending_state;
                    gst_message_parse_state_changed(msg, &old_state, &new_state, &pending_state);
                    g_print("Pipeline state changed from %s to %s:\n",
                            gst_element_state_get_name(old_state), gst_element_state_get_name(new_state));
                }
                break;
            default:
                /* We should not reach here */
                g_printerr("Unexpected message received.\n");
                break;
            }
            gst_message_unref(msg);
        }
    } while (!terminate);

    /* Free resources */
    gst_object_unref(bus);
    gst_element_set_state(data.pipeline, GST_STATE_NULL);
    gst_object_unref(data.pipeline);
    return 0;
}

/* This function will be called by the pad-added signal */
static void pad_added_handler(GstElement *src, GstPad *new_pad, CustomData *data)
{
    GstPad *sink_pad = gst_element_get_static_pad(data->convert, "sink");
    GstPadLinkReturn ret;
    GstCaps *new_pad_caps = NULL;
    GstStructure *new_pad_struct = NULL;
    const gchar *new_pad_type = NULL;

    g_print("Received new pad '%s' from '%s':\n", GST_PAD_NAME(new_pad), GST_ELEMENT_NAME(src));

    /* If our converter is already linked, we have nothing to do here */
    if (gst_pad_is_linked(sink_pad))
    {
        g_print("We are already linked. Ignoring.\n");
        goto exit;
    }

    /* Check the new pad's type */
    new_pad_caps = gst_pad_get_current_caps(new_pad);
    new_pad_struct = gst_caps_get_structure(new_pad_caps, 0);
    new_pad_type = gst_structure_get_name(new_pad_struct);
    if (!g_str_has_prefix(new_pad_type, "audio/x-raw"))
    {
        g_print("It has type '%s' which is not raw audio. Ignoring.\n", new_pad_type);
        goto exit;
    }

    /* Attempt the link */
    ret = gst_pad_link(new_pad, sink_pad);
    if (GST_PAD_LINK_FAILED(ret))
    {
        g_print("Type is '%s' but link failed.\n", new_pad_type);
    }
    else
    {
        g_print("Link succeeded (type '%s').\n", new_pad_type);
    }

exit:
    /* Unreference the new pad's caps, if we got them */
    if (new_pad_caps != NULL)
        gst_caps_unref(new_pad_caps);

    /* Unreference the sink pad */
    gst_object_unref(sink_pad);
}
```

* Complie code:

```bash
gcc basic_tutorial_3.c -o basic_tutorial_3 `pkg-config --cflags --libs gstreamer-1.0`
```

* Run:

```bash
./basic_tutorial_3
```

Bài hướng dẫn này chỉ chạy âm thanh. Media được tải xuống từ Internet, vì vậy có thể mất vài giây để bắt đầu phụ thuộc vào tốc độ kết nối của bạn.

# Walkthrough

```c
typedef struct _CustomData
{
    GstElement *pipeline;
    GstElement *source;
    GstElement *convert;
    GstElement *resample;
    GstElement *sink;
} CustomData;
```

Cho đến nay chúng ta đã giữ tất cả thông tin chúng ta cần (về cơ bản là các con trỏ trỏ tới các `GstElement`) dưới dạng các biến cục bộ (local variables). Vì bài hướng dẫn này (và hầu hết các ứng dụng thực tế) liên quan đến các callbacks, chúng ta sẽ nhóm tất cả dữ liệu của chúng ta trong một cấu trúc để dễ dàng xử lý.

```c
static void pad_added_handler(GstElement *src, GstPad *new_pad, CustomData *data)
```

Nó cho phép chuyển tiếp tham chiếu, sẽ được sử dụng sau này.

```c
data.source = gst_element_factory_make("uridecodebin", "source");
data.convert = gst_element_factory_make("audioconvert", "convert");
data.resample = gst_element_factory_make("audioresample", "resample");
data.sink = gst_element_factory_make("autoaudiosink", "sink");
```

Chúng ta sẽ tạo các phần tử như bình thường. `uridencodebin` sẽ khởi tạo bên trong tất cả các phần tử cần thiết (sources, demuxers, decoders) để biến URI thành luồng âm thanh và/hoặc video. Nó thực hiện một nửa công việc mà `playbin` làm. Vì nó chứa các bộ giải mã (demuxer), nên các source pads không có sẵn và chúng ta sẽ cần liên kết với chúng một cách nhanh chóng.

`audioconvert` hữu ích khi chuyển đổi giữa các định dạng âm thanh khác nhau, đảm bảo rằng ví dụ này sẽ hoạt động trên mọi nền tảng, vì định dạng do bộ giải mã âm thanh tạo ra có thể không giống với định dạng âm thanh sink mong muốn.

`audioresample` hữu ích khi chuyển đổi giữa các tốc độ lấy mẫu âm thanh khác nhau, tương tự, đảm bảo rằng ví dụ này sẽ hoạt động trên mọi nền tảng, vì tốc độ lấy mẫu âm thanh do bộ giải mã tạo ra  có thể không phải tốc độ mà phần âm thanh sink hỗ trợ.

`autoaudiosink` tương đương với `autovideosink` đã thấy trong bài hướng dẫn trước. Nó sẽ render luồng âm thanh tới card âm thanh.

```c
if (!gst_element_link_many(data.convert, data.resample, data.sink, NULL))
    {
        g_printerr("Elements could not be linked.\n");
        gst_object_unref(data.pipeline);
        return -1;
    }
```

### Signals

### The callback

### GStreamer States

# Exercise

# Conclusion

----

# References

* [Basic tutorial 3: Dynamic pipelines](https://gstreamer.freedesktop.org/documentation/tutorials/basic/dynamic-pipelines.html?gi-language=c)
